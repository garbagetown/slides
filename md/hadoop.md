# ビッグデータ開発

---

## 目次
- ビッグデータとは
- 工程ごとの留意点
  - 要件定義
    - 機能要件
    - システム要件
  - 基本設計
    - データフロー
    - データモデリング
  - 詳細設計
    - 抽出
    - 加工
    - 登録
  - 製造
    - 環境構築
    - 単体試験
  - 結合試験
    - 機能試験
  - 総合試験
    - 性能試験
  - 運用保守
    - 故障解析
    - 性能改善

---

## ビッグデータとは

そもそもビッグデータとは何か。Wikipedia では以下のように定義している。

> 市販されているデータベース管理ツールや従来のデータ処理アプリケーションで処理することが困難なほど巨大で複雑なデータ集合の集積物を表す用語
- [ビッグデータ - Wikipedia](https://ja.wikipedia.org/wiki/%E3%83%93%E3%83%83%E3%82%B0%E3%83%87%E3%83%BC%E3%82%BF)

言い換えれば、市販されているデータベース管理ツールや従来のデータ処理アプリケーションで処理できる大きさ、複雑さであれば、ビッグデータではない。

では、処理することが困難な大きさ、複雑さとは何か。

### 大きさ

ハードウェアの処理能力を上回る大きさと考えればよい。

従来の HDD の処理能力は 80MB/s 程度であり、例えば 3TB のデータを読み出すのに 10 時間以上かかる。

> (3 x 1,000 x 1,000) / (80 x 60 x 60) = 625 (分) = 10.41 (時間)

これを 600 台で分散すれば 1 分程度で読み出せるというシンプルな発想が、並列分散処理の基本的な考え方である。


### 複雑さ

非正規化データと考えればよい。

SNS のデータなど自然言語である場合が多く、形態素解析ツールなどを活用すれば処理できるが、統計分析に十分な母数が必要であり、結果的に上述の大きさの問題に帰結する場合が多い。

SSD や メモリの大容量/低価格化が進めば、従来のデータ処理アプリケーションで処理可能となり、特に並列分散処理する必要がなくなることに留意しなければならない。

---

## 要件転義

### 機能要件

### システム要件

---

## 基本設計

### データフロー

### データモデリング

---

## 詳細設計

### 抽出

### 加工

### 登録

---

## 製造

### 環境構築

### 単体試験

---

## 結合試験

### 機能試験

---

## 総合試験

### 性能試験

--- 

## 運用保守

### 故障解析

### 性能改善
